"""
wrapper定义文件
"""
from ding.envs.env_wrappers import MaxAndSkipWrapper, WarpFrameWrapper, ScaledFloatFrameWrapper, FrameStackWrapper, \
    FinalEvalRewardEnv
import gym
import numpy as np


class StickyActionWrapper(gym.ActionWrapper):
    """
    Overview:
       A certain possibility to select the last action
    Interface:
        ``__init__``, ``action``
    Properties:
        - env (:obj:`gym.Env`): the environment to wrap.
        - ``p_sticky``: possibility to select the last action
    """

    def __init__(self, env: gym.Env, p_sticky: float=0.25):
        super().__init__(env)
        self.p_sticky = p_sticky
        self.last_action = 0

    def action(self, action):
        if np.random.random() < self.p_sticky:
            return_action = self.last_action
        else:
            return_action = action
        self.last_action = action
        return return_action


class SparseRewardWrapper(gym.Wrapper):
    """
    Overview:
       Only death and pass sparse reward
    Interface:
        ``__init__``, ``step``
    Properties:
        - env (:obj:`gym.Env`): the environment to wrap.
    """

    def __init__(self, env: gym.Env):
        super().__init__(env)

    def step(self, action):
        obs, reward, done, info = self.env.step(action)
        dead = True if reward == -15 else False
        reward = 0
        if info['flag_get']:
            reward = 15
        if dead:
            reward = -15
        return obs, reward, done, info


class CoinRewardWrapper(gym.Wrapper):
    """
    Overview:
        add coin reward
    Interface:
        ``__init__``, ``step``
    Properties:
        - env (:obj:`gym.Env`): the environment to wrap.
    """

    def __init__(self, env: gym.Env):
        super().__init__(env)
        self.num_coins = 0

    def step(self, action):
        obs, reward, done, info = self.env.step(action)
        reward += (info['coins'] - self.num_coins) * 10
        self.num_coins = info['coins']
        return obs, reward, done, info
